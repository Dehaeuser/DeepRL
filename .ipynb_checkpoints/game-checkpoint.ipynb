{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03b1cec7-61ed-4066-9b89-28f7d3d25c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow_probability as tfp\n",
    "from vocab import Vocabulary\n",
    "from env import ConceptData\n",
    "from create_data import addFile\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "import create_data\n",
    "from xml.dom import minidom\n",
    "import xml.etree.ElementTree as ET\n",
    "from vocab import Vocabulary\n",
    "from env import ConceptData\n",
    "from create_data import addFile\n",
    "import agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bad41f30-054a-4293-949a-c997256a8d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "hidden_size = 44\n",
    "num_distractors = 7\n",
    "#ist an sich vorgegeben und 597 oder so\n",
    "num_categories = 58\n",
    "vocab_size = 99\n",
    "embed_dim = 50\n",
    "max_len = 5\n",
    "num_epochs = 12\n",
    "sender_entropy_coeff = 0.015 #wie bei Ossenkopf\n",
    "receiver_entropy_coeff = 0.0 # wie bei Ossenkopf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f224a1c4-05bd-4850-bc4a-1ea13263b5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_concepts:\n",
      "[<DOM Element: concept at 0x202fc0eb670>, <DOM Element: concept at 0x202fb311a60>, <DOM Element: concept at 0x202fbfab9d0>, <DOM Element: concept at 0x202fc1448b0>, <DOM Element: concept at 0x202fbf9b670>, <DOM Element: concept at 0x202fc0eb8b0>, <DOM Element: concept at 0x202fb87b040>, <DOM Element: concept at 0x202fc08ce50>, <DOM Element: concept at 0x202fbf865e0>, <DOM Element: concept at 0x202fc0eb4c0>]\n",
      "target_concept:\n",
      "<DOM Element: concept at 0x202fc08ce50>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#im folgenden tun wir so als wäre vocab unsere daten\n",
    "#vocab ist ninput für Receiver\n",
    "vocab = tf.random.categorical(tf.math.log([[0.5, 0.5]]), \n",
    "                              12992)\n",
    "\n",
    "vocab = tf.reshape(vocab, [7,32,58])\n",
    "\n",
    "#Input für sender\n",
    "speakerInput = vocab[:][:][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9b8c98-d3e8-4f03-a1df-7dd739638fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weil sender noch nicht tut, nemen wir das als dummy für message die eig von sender outgeputtet wird\n",
    "message = tf.constant([[89, 37, 86, 72,  0],\n",
    "        [ 9, 85, 11, 20,  0],\n",
    "        [25, 16, 20, 12,  0],\n",
    "        [97,  0, 26, 89,  0],\n",
    "        [45, 86, 34, 43,  0],\n",
    "        [49, 91, 59, 56,  0],\n",
    "        [80, 63, 70, 53,  0],\n",
    "        [96, 57, 98, 54,  0],\n",
    "        [41, 10, 92, 83,  0],\n",
    "        [71, 45, 70, 51,  0],\n",
    "        [89, 59, 45, 52,  0],\n",
    "        [62, 33, 94, 11,  0],\n",
    "        [55, 91, 16, 74,  0],\n",
    "        [17, 77, 15, 78,  0],\n",
    "        [93, 61, 12, 46,  0],\n",
    "        [32, 38, 93, 46,  0],\n",
    "        [73, 86, 78, 85,  0],\n",
    "        [63, 74, 85, 92,  0],\n",
    "        [52,  6, 41, 51,  0],\n",
    "        [ 6, 60, 61, 37,  0],\n",
    "        [61, 44, 32,  8,  0],\n",
    "        [ 8, 67, 83, 64,  0],\n",
    "        [ 4, 74, 57, 96,  0],\n",
    "        [91, 75, 74, 50,  0],\n",
    "        [71, 24,  6, 14,  0],\n",
    "        [26, 79, 59, 43,  0],\n",
    "        [66, 54, 25,  2,  0],\n",
    "        [28,  7, 74, 92,  0],\n",
    "        [12, 59, 44, 93,  0],\n",
    "        [ 3, 38, 21, 10,  0],\n",
    "        [14, 35, 80,  2,  0],\n",
    "        [21, 11, 10, 64,  0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff03c97e-b604-4682-a6db-753df72a5b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialisiere die Agents\n",
    "speakerEncoder = agents.Encoder(units = 44, categories_dim = 58)\n",
    "speakerDecoder = agents.Sender_LSTM(vocab_size, embed_dim, hidden_size, max_len )\n",
    "receiverEncoder = agents.Receiver(num_distractors)\n",
    "receiverDecoder = agents.Receiver_LSTM(receiverEncoder, vocab_size, embed_dim, hidden_size)\n",
    "guesser = agents.AuxillaryNetwork(hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f6fd4ce-3608-4b63-9b00-22183bbb1198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prev_hidden kommt von sender; müssen wir hier faken\n",
    "prev_hidden = tf.random.normal([32,44])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89bc405d-46b2-45c7-bf88-8e737c6cd6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "guesser_output = guesser(prev_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "336f56cf-7880-4115-9c22-5cdc70d0c4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the losses\n",
    "#loss um prediction mit Realität zu vergleichen\n",
    "#für was brauchen wir die underscore variablen?\n",
    "\n",
    "def loss(_sender_input, _message, _receiver_input, receiver_output, labels):\n",
    "    \"\"\"\n",
    "    receiver_output ist was von receiver_sampling zurückgegeben wird\n",
    "    LABELS PRINTEN IN OSSSENKOPF NOTEBOOK\n",
    "    \"\"\"\n",
    "    acc = (labels.t() == receiver_output).float() - (labels.t() != receiver_output).float()\n",
    "    return -acc, {'acc': (acc.mean().item()+1)/2}\n",
    "\n",
    "#loss um prediction mit Realität zu vergleichen\n",
    "def auxiliary_loss(receiver_thoughts, \n",
    "                  # _message, _receiver_input, \n",
    "                   guesser_output, \n",
    "                   #_labels,\n",
    "                   weight=0.2):\n",
    "    mae = tf.keras.losses.MeanAbsoluteError(reduction = 'none')\n",
    "    loss = mae(receiver_thoughts, guesser_output,)\n",
    "    loss *= weight\n",
    "    return loss, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be22afbf-c5fb-4a29-b5fd-be61aff07255",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_guesser = tf.keras.optimizers.Adam(learning_rate = 1e-2)\n",
    "optim_receiver = tf.keras.optimizers.Adam(learning_rate = 1e-2)\n",
    "optim_sender = tf.keras.optimizers.Adam(learning_rate = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b509be3b-ed51-41e7-aefc-33cb108cf9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_epochs):\n",
    "    # 1. data holen, labels?\n",
    "    ####Fehlt hier noch\n",
    "    \n",
    "    \n",
    "    ##2. durch agents laufen lassen\n",
    "    output_sender = speakerEncoder(speakerInput)\n",
    "    message, log_prob_s, entropy_s , prev_hidden = speakerDecoder(output_sender)\n",
    "    sample, log_prob_r, entropy_r, last_hidden = receiverDecoder(message, batch_size, max_len,vocab)\n",
    "    guesser_output = guesser(prev_hidden)\n",
    "        \n",
    "    \n",
    "    # 3. Loss berechnen\n",
    "    auxLoss = auxiliary_loss(last_hidden, guesser_output)\n",
    "    # labels fehlen noch\n",
    "    loss = loss(sample, labels)\n",
    "    ##policy_length_loss und das baseline Zeug miteinbringen?\n",
    "    weighted_entropy = entropy_r * receiver_entropy_coeff + sender_entropy_coeff # *entropy_r\n",
    "    log_prob = log_prob_r # + log_prob_s\n",
    "    loss = tf.math.reduce_mean(loss* log_prob) - weighted_entropy\n",
    "    \n",
    "    #optimization\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        # muss der eine Receiver im Konstruktor vom anderem erstellt werden damit das funktioniert?\n",
    "        receiver_gradients = tape.gradient(loss, receiverDecoder.trainable_variables)\n",
    "        print(receiver_gradients)\n",
    "    optim_receiver.apply_gradients(zip(receiver_gradients, receiverDecoder.trainable_variables))\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        guesser_gradients = tape.gradient(auxLoss, guesser.trainable_variables)\n",
    "        print(guesser_gradients)\n",
    "    optim_guesser.apply_gradients(zip(guesser_gradients, guesser.trainable_variables))\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        senderLSTM_gradients = tape.gradient(loss, speakerDecoder.trainable)\n",
    "        senderEncoder_gradients = guesser_gradients + senderLSTM_gradients\n",
    "    optim_sender.apply_gradients(zip(senderLSTM_gradients, speakerDecoder.trainable_variables))\n",
    "    optim_sender.apply_gradients(zip(senderEncoder_gradients, senderEncoder.trainable_variables))\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    #testing <-> trainifehlt noch\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
