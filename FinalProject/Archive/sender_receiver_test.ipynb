{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow_probability as tfp\n",
    "from vocab import Vocabulary\n",
    "from env import ConceptData\n",
    "from create_data import addFile\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "import create_data\n",
    "from xml.dom import minidom\n",
    "import xml.etree.ElementTree as ET\n",
    "from vocab import Vocabulary\n",
    "from env2 import ConceptData\n",
    "from create_data import addFile\n",
    "import agents\n",
    "from agents import find_lengths\n",
    "import sender2\n",
    "import game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sender_encoder = sender2.Sender(num_options=10, batch_size=32)\n",
    "sender_only_target = sender2.SenderOnlyTarget(batch_size=32)\n",
    "sender = sender2.Sender_LSTM(agent = sender_only_target, vocab_size=99, embed_dim=44, num_cells=1, hidden_size=1, max_len=10, see_all_input=False)\n",
    "receiver_decoder = agents.Receiver(num_options=10)\n",
    "receiver_encoder = agents.Receiver_LSTM(agent=receiver_decoder, vocab_size=99, embed_dim=44, hidden_size=44, masking_value=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = Vocabulary()\n",
    "\n",
    "def addFile(name):\n",
    "    file_name = name + \"_structured_final.xml\"\n",
    "    file = minidom.parse(os.path.join(os.path.join('visa_dataset', 'UK'), file_name))\n",
    "    concepts = file.getElementsByTagName('concept')\n",
    "\n",
    "    for concept in concepts:\n",
    "        vocabulary.addConcept(concept)\n",
    "\n",
    "\n",
    "addFile(\"ANIMALS\")\n",
    "addFile(\"APPLIANCES\")\n",
    "addFile(\"ARTEFACTS\")\n",
    "addFile(\"CLOTHING\")\n",
    "addFile(\"CONTAINER\")\n",
    "addFile(\"DEVICE\")\n",
    "addFile(\"FOOD\")\n",
    "addFile(\"HOME\")\n",
    "addFile(\"INSTRUMENTS\")\n",
    "addFile(\"MATERIAL\")\n",
    "addFile(\"PLANTS\")\n",
    "addFile(\"STRUCTURES\")\n",
    "addFile(\"TOOLS\")\n",
    "addFile(\"TOYS\")\n",
    "addFile(\"VEHICLES\")\n",
    "addFile(\"WEAPONS\")\n",
    "\n",
    "for concept in vocabulary.concept_list:\n",
    "    vocabulary.parseConcept(concept)\n",
    "    \n",
    "data = ConceptData(vocabulary, 9, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_concepts, sender_input, targets, receiver_input = data.getInputDifferent()\n",
    "#print(sender_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message:\n",
      "tf.Tensor(\n",
      "[[86 87  2 36  2 46 96 16 80  0  0  0  0  0  0  0  0  0]\n",
      " [22 55 83 61 39 36 30 82 74  0  0  0  0  0  0  0  0  0]\n",
      " [37 35  7 57 93 26 24 72 25  0  0  0  0  0  0  0  0  0]\n",
      " [79 13 37 94 58  8 83 57 33  0  0  0  0  0  0  0  0  0]\n",
      " [53 76  0  4 70 27 14 41 34  0  0  0  0  0  0  0  0  0]\n",
      " [33 46 23  7 85 34 85 26 32  0  0  0  0  0  0  0  0  0]\n",
      " [87 29 96 29  1 86 87 15 91  0  0  0  0  0  0  0  0  0]\n",
      " [52 44 41 26 14 29  5 42 59  0  0  0  0  0  0  0  0  0]\n",
      " [80 13 71 11 72 57  3 79 50  0  0  0  0  0  0  0  0  0]\n",
      " [15 57 41 32 77 69 29 94 25  0  0  0  0  0  0  0  0  0]\n",
      " [18 92 29  8 87  1 74 44  6  0  0  0  0  0  0  0  0  0]\n",
      " [75  6 75  4 62 82 50 97 47  0  0  0  0  0  0  0  0  0]\n",
      " [26  2 59 73 65 68 98 35 54  0  0  0  0  0  0  0  0  0]\n",
      " [59  6 56 70 23 65 35 61 29  0  0  0  0  0  0  0  0  0]\n",
      " [ 5 63 58 36 28 66 15 96 10  0  0  0  0  0  0  0  0  0]\n",
      " [70  2 43 66 23 16 97 76  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 3 78 24 47 15  3 51 10 54  0  0  0  0  0  0  0  0  0]\n",
      " [92 27 97 18 90  0 63 17 63  0  0  0  0  0  0  0  0  0]\n",
      " [66 70  0 78 95 18 83 30 47  0  0  0  0  0  0  0  0  0]\n",
      " [22 46 92 94 80 97 33 57 52  0  0  0  0  0  0  0  0  0]\n",
      " [21  9 25 32 85 62 75 41 13  0  0  0  0  0  0  0  0  0]\n",
      " [27 36 57 82 63 28 85 63 81  0  0  0  0  0  0  0  0  0]\n",
      " [90 23 20 83 80 17 91 24 86  0  0  0  0  0  0  0  0  0]\n",
      " [91 83 73 24 53 32 67 86  3  0  0  0  0  0  0  0  0  0]\n",
      " [63  6 80 16 35 81 90 63 30  0  0  0  0  0  0  0  0  0]\n",
      " [70 22 97 49 91 44 55 11 77  0  0  0  0  0  0  0  0  0]\n",
      " [70 61  4 89 94 52 52  1 93  0  0  0  0  0  0  0  0  0]\n",
      " [65  6 65 86 33 89 19 66 70  0  0  0  0  0  0  0  0  0]\n",
      " [13 59 39 87 61 43 27 83 72  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 59 41 49 97 30  6 80 34  0  0  0  0  0  0  0  0  0]\n",
      " [18 80 50 39 88 26  8 73 76  0  0  0  0  0  0  0  0  0]\n",
      " [83 71 74 48 61 76 65 56  1  0  0  0  0  0  0  0  0  0]], shape=(32, 18), dtype=int32)\n",
      "logits:\n",
      "tf.Tensor(\n",
      "[[-4.5778933 -4.597066  -4.607253  -4.5993195 -4.5994544 -4.5978494\n",
      "  -4.593623  -4.5953245 -4.5955715  0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.       ]\n",
      " [-4.610167  -4.5805902 -4.5842047 -4.5944853 -4.5932045 -4.596713\n",
      "  -4.5956054 -4.595768  -4.5952444  0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.       ]\n",
      " [-4.6250525 -4.580657  -4.591597  -4.593645  -4.596659  -4.5958614\n",
      "  -4.594023  -4.595625  -4.594993   0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.       ]\n",
      " [-4.597374  -4.59878   -4.604656  -4.597977  -4.5967894 -4.596372\n",
      "  -4.5938997 -4.594944  -4.595126   0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.       ]\n",
      " [-4.615894  -4.6165237 -4.595112  -4.597047  -4.596647  -4.5921783\n",
      "  -4.595867  -4.5948167 -4.594541   0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.       ]\n",
      " [-4.5957823 -4.618131  -4.586321  -4.5928893 -4.5932713 -4.59243\n",
      "  -4.594446  -4.5954065 -4.595481   0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.       ]\n",
      " [-4.598568  -4.6010637 -4.583127  -4.5971866 -4.593771  -4.5937123\n",
      "  -4.595271  -4.5948796 -4.5951147  0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.       ]\n",
      " [-4.5756464 -4.606791  -4.5911436 -4.5973167 -4.597253  -4.5958858\n",
      "  -4.594761  -4.5952444 -4.594452   0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.       ]\n",
      " [-4.6215    -4.5991898 -4.6060076 -4.590312  -4.5973854 -4.594591\n",
      "  -4.5961986 -4.5951858 -4.5950956  0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.       ]\n",
      " [-4.586929  -4.5908637 -4.5913076 -4.5994925 -4.59844   -4.592966\n",
      "  -4.595564  -4.5955524 -4.59499    0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.       ]\n",
      " [-4.5933213 -4.611714  -4.598394  -4.5989113 -4.5955124 -4.5943527\n",
      "  -4.595439  -4.595612  -4.5953317  0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.       ]\n",
      " [-4.578864  -4.6029205 -4.5892406 -4.597002  -4.5968018 -4.5968275\n",
      "  -4.595053  -4.595561  -4.5953975  0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.       ]\n",
      " [-4.604835  -4.615735  -4.582092  -4.5877075 -4.5913796 -4.595318\n",
      "  -4.595414  -4.594447  -4.5952616  0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.       ]\n",
      " [-4.5601406 -4.6025753 -4.6025686 -4.597505  -4.5922556 -4.592936\n",
      "  -4.5940437 -4.5950413 -4.5952725  0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.       ]\n",
      " [-4.5880427 -4.602993  -4.6004157 -4.599389  -4.59502   -4.5976458\n",
      "  -4.5947337 -4.5941997 -4.5947175  0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.       ]\n",
      " [-4.6077027 -4.6173034 -4.590441  -4.6024995 -4.5919504 -4.5957212\n",
      "  -4.595894  -4.596145  -4.595118   0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.       ]\n",
      " [-4.6184864 -4.5859146 -4.5867805 -4.5985556 -4.5940795 -4.596916\n",
      "  -4.5965753 -4.5944667 -4.5952616  0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.       ]\n",
      " [-4.625063  -4.571097  -4.601106  -4.594666  -4.59067   -4.5951133\n",
      "  -4.595752  -4.595462  -4.595351   0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.       ]\n",
      " [-4.6287475 -4.6024666 -4.5951123 -4.5917354 -4.5994916 -4.5949583\n",
      "  -4.5937123 -4.5954103 -4.595405   0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.       ]\n",
      " [-4.60948   -4.6168294 -4.605139  -4.5983276 -4.598533  -4.596325\n",
      "  -4.59514   -4.5949235 -4.5948043  0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.       ]\n",
      " [-4.569841  -4.575994  -4.592411  -4.599511  -4.5933228 -4.596157\n",
      "  -4.594333  -4.5948167 -4.5952373  0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.       ]\n",
      " [-4.5590625 -4.606964  -4.592698  -4.59974   -4.5967216 -4.5950603\n",
      "  -4.594494  -4.5954723 -4.5946136  0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.       ]\n",
      " [-4.564509  -4.5818243 -4.5973644 -4.589208  -4.598353  -4.5959544\n",
      "  -4.5951066 -4.594489  -4.594835   0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.       ]\n",
      " [-4.595007  -4.5790877 -4.5837626 -4.590556  -4.5974555 -4.5965247\n",
      "  -4.5942335 -4.5946674 -4.595485   0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.       ]\n",
      " [-4.6084447 -4.603152  -4.6049814 -4.5967383 -4.5919547 -4.5927176\n",
      "  -4.5935507 -4.5954905 -4.5952954  0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.       ]\n",
      " [-4.606707  -4.6036835 -4.600648  -4.5928917 -4.595084  -4.596478\n",
      "  -4.5940614 -4.5944824 -4.5955462  0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.       ]\n",
      " [-4.606983  -4.593422  -4.598304  -4.5887356 -4.5970564 -4.593686\n",
      "  -4.5942535 -4.5948305 -4.5953264  0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.       ]\n",
      " [-4.5676994 -4.6024065 -4.5852413 -4.5915947 -4.5951724 -4.5929604\n",
      "  -4.5957513 -4.5959816 -4.5953064  0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.       ]\n",
      " [-4.602169  -4.57239   -4.589883  -4.5958076 -4.594744  -4.5941486\n",
      "  -4.5933504 -4.594276  -4.5954328  0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.       ]\n",
      " [-4.630201  -4.5723257 -4.5913014 -4.5928035 -4.5971694 -4.5959105\n",
      "  -4.595726  -4.5958896 -4.5945425  0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.       ]\n",
      " [-4.593326  -4.61089   -4.594643  -4.592144  -4.5957804 -4.595843\n",
      "  -4.5959444 -4.594158  -4.5956883  0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.       ]\n",
      " [-4.5642304 -4.6151204 -4.597813  -4.597746  -4.5947294 -4.597918\n",
      "  -4.593664  -4.595766  -4.5949354  0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.       ]], shape=(32, 18), dtype=float32)\n",
      "entropy:\n",
      "tf.Tensor(\n",
      "[[4.5949235 4.5950475 4.5950937 4.5951104 4.5951157 4.5951195 4.5951195\n",
      "  4.5951204 4.5951185 0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.       ]\n",
      " [4.5949    4.5950384 4.595092  4.595109  4.5951157 4.5951176 4.5951195\n",
      "  4.5951185 4.5951204 0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.       ]\n",
      " [4.5949187 4.595044  4.595095  4.5951114 4.595115  4.595119  4.595119\n",
      "  4.59512   4.59512   0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.       ]\n",
      " [4.594961  4.5950613 4.595101  4.5951123 4.5951176 4.595119  4.59512\n",
      "  4.59512   4.5951204 0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.       ]\n",
      " [4.5949063 4.5950413 4.5950923 4.59511   4.5951176 4.5951195 4.5951195\n",
      "  4.595119  4.5951195 0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.       ]\n",
      " [4.5948954 4.5950365 4.595092  4.5951104 4.5951166 4.595119  4.5951214\n",
      "  4.59512   4.595119  0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.       ]\n",
      " [4.594902  4.5950384 4.5950937 4.5951085 4.5951157 4.59512   4.5951195\n",
      "  4.595119  4.595119  0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.       ]\n",
      " [4.5948887 4.595036  4.59509   4.5951085 4.595116  4.595117  4.59512\n",
      "  4.5951195 4.5951185 0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.       ]\n",
      " [4.5949235 4.595048  4.595095  4.595112  4.595116  4.595118  4.5951185\n",
      "  4.5951204 4.595121  0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.       ]\n",
      " [4.594908  4.5950418 4.5950933 4.5951114 4.595115  4.595118  4.5951185\n",
      "  4.5951185 4.5951195 0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.       ]\n",
      " [4.5949287 4.5950494 4.595094  4.5951114 4.5951157 4.5951195 4.5951185\n",
      "  4.5951204 4.5951204 0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.       ]\n",
      " [4.5949183 4.5950456 4.5950937 4.595111  4.595117  4.595119  4.5951185\n",
      "  4.595119  4.595121  0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.       ]\n",
      " [4.5949216 4.5950475 4.5950937 4.5951104 4.595117  4.5951185 4.5951195\n",
      "  4.595121  4.595118  0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.       ]\n",
      " [4.5949345 4.5950513 4.595095  4.5951123 4.5951157 4.5951185 4.5951195\n",
      "  4.5951204 4.5951195 0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.       ]\n",
      " [4.594915  4.595045  4.5950937 4.5951104 4.595116  4.595121  4.5951195\n",
      "  4.5951204 4.5951195 0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.       ]\n",
      " [4.5948906 4.595033  4.5950904 4.5951095 4.595115  4.5951185 4.595118\n",
      "  4.5951185 4.5951204 0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.       ]\n",
      " [4.5949216 4.5950465 4.5950956 4.59511   4.5951176 4.5951176 4.5951195\n",
      "  4.5951204 4.5951185 0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.       ]\n",
      " [4.5948906 4.595036  4.5950904 4.5951085 4.595114  4.5951185 4.5951195\n",
      "  4.595119  4.5951195 0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.       ]\n",
      " [4.5949044 4.5950427 4.595093  4.595109  4.595117  4.595119  4.5951204\n",
      "  4.5951195 4.5951204 0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.       ]\n",
      " [4.594919  4.595046  4.5950933 4.595112  4.5951157 4.595119  4.5951185\n",
      "  4.595119  4.5951204 0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.       ]\n",
      " [4.5949078 4.5950403 4.5950947 4.5951095 4.595116  4.595118  4.59512\n",
      "  4.59512   4.5951204 0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.       ]\n",
      " [4.594926  4.595048  4.595094  4.5951095 4.595118  4.5951185 4.595121\n",
      "  4.595119  4.5951204 0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.       ]\n",
      " [4.5949397 4.5950522 4.5950966 4.595112  4.595116  4.5951195 4.5951214\n",
      "  4.5951195 4.5951214 0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.       ]\n",
      " [4.5949535 4.59506   4.595099  4.5951123 4.5951176 4.595119  4.5951204\n",
      "  4.59512   4.5951204 0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.       ]\n",
      " [4.5949044 4.5950427 4.595093  4.595109  4.595117  4.595119  4.5951204\n",
      "  4.5951195 4.5951204 0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.       ]\n",
      " [4.5949254 4.595049  4.5950933 4.5951123 4.595116  4.595118  4.5951185\n",
      "  4.5951204 4.59512   0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.       ]\n",
      " [4.5949154 4.595044  4.595092  4.5951104 4.595116  4.5951195 4.595119\n",
      "  4.59512   4.59512   0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.       ]\n",
      " [4.594943  4.5950546 4.5950966 4.5951133 4.595118  4.595119  4.59512\n",
      "  4.5951204 4.5951204 0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.       ]\n",
      " [4.5949097 4.5950418 4.5950933 4.59511   4.595117  4.5951185 4.5951195\n",
      "  4.595119  4.5951185 0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.       ]\n",
      " [4.5949097 4.595043  4.595093  4.59511   4.5951166 4.5951195 4.59512\n",
      "  4.595119  4.59512   0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.       ]\n",
      " [4.5949287 4.5950503 4.5950956 4.595112  4.595117  4.5951185 4.59512\n",
      "  4.5951195 4.595119  0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.       ]\n",
      " [4.594892  4.5950356 4.595091  4.5951104 4.5951166 4.59512   4.5951195\n",
      "  4.5951204 4.595119  0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.       ]], shape=(32, 18), dtype=float32)\n",
      "state_h:\n",
      "tf.Tensor(\n",
      "[[-0.00254686]\n",
      " [-0.00267294]\n",
      " [-0.00256085]\n",
      " [-0.00229388]\n",
      " [-0.00263329]\n",
      " [-0.00270981]\n",
      " [-0.00265936]\n",
      " [-0.00273296]\n",
      " [-0.0025291 ]\n",
      " [-0.00262438]\n",
      " [-0.00250782]\n",
      " [-0.00257422]\n",
      " [-0.00254881]\n",
      " [-0.00246865]\n",
      " [-0.00258818]\n",
      " [-0.00272803]\n",
      " [-0.00254407]\n",
      " [-0.00273023]\n",
      " [-0.00264474]\n",
      " [-0.00256753]\n",
      " [-0.00263517]\n",
      " [-0.00251776]\n",
      " [-0.00243414]\n",
      " [-0.00233719]\n",
      " [-0.00264474]\n",
      " [-0.00253059]\n",
      " [-0.00258501]\n",
      " [-0.00241667]\n",
      " [-0.0026214 ]\n",
      " [-0.00262863]\n",
      " [-0.00249811]\n",
      " [-0.0027212 ]], shape=(32, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#sender_encoded = sender_encoder(sender_input)\n",
    "#sender_input = tf.squeeze(tf.convert_to_tensor(sender_input))\n",
    "#print(sender_input)\n",
    "sender_input = tf.transpose(sender_input, [1,0,2])\n",
    "sender_input = sender_input.numpy()\n",
    "\n",
    "message, log_prob_s, entropy_s, state_h = sender(sender_input)\n",
    "print(\"message:\")\n",
    "print(message)\n",
    "print(\"logits:\")\n",
    "print(log_prob_s)\n",
    "print(\"entropy:\")\n",
    "print(entropy_s)\n",
    "print(\"state_h:\")\n",
    "print(state_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy_r_shape  (32,)\n",
      "entropy_s_shape  (32, 18)\n",
      "message_lengths:  [10, 10, 10, 10, 3, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 9, 10, 6, 3, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.09375"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#einer- Dimension rausbekommen\n",
    "receiver_input = tf.squeeze(tf.convert_to_tensor(receiver_input))\n",
    "#richtige Reihenfolge der Dimensionen\n",
    "receiver_input2 = tf.transpose(receiver_input, [1,0,2])\n",
    "receiver_input2 = receiver_input2.numpy()\n",
    "\n",
    "sample, log_prob_r, entropy_r, last_hidden = receiver_encoder(message=message, batch_size=32, max_len=10, receiver_input=receiver_input2)\n",
    "\n",
    "print('entropy_r_shape ', entropy_r.shape)\n",
    "print('entropy_s_shape ', entropy_s.shape)\n",
    "message_lengths = find_lengths(message)\n",
    "print('message_lengths: ', message_lengths)\n",
    "\n",
    "effective_entropy_s = tf.zeros_like(entropy_r)\n",
    "effective_entropy_s = np.array(effective_entropy_s)\n",
    "effective_log_prob_s = tf.zeros_like(log_prob_r)\n",
    "effective_log_prob_s = np.array(effective_log_prob_s)\n",
    "\n",
    "#print(message.shape)\n",
    "\n",
    "for k in range(message.shape[0]):\n",
    "    for l in range(message.shape[1]):\n",
    "        not_eosed = float(k < message_lengths[k])\n",
    "        effective_entropy_s[k] += entropy_s[k, l] * not_eosed\n",
    "        effective_log_prob_s[k] += log_prob_s[k, l] * not_eosed\n",
    "        \n",
    "effective_entropy_s = tf.convert_to_tensor(effective_entropy_s)\n",
    "effective_log_prob_s = tf.convert_to_tensor(effective_log_prob_s)\n",
    "        \n",
    "receiver_output = []\n",
    "for i in range(32):\n",
    "    receiver_output.append(input_concepts[i][sample[i]])\n",
    "    #print(targets[i] == receiver_output[i])\n",
    "\n",
    "#targets = tf.constant(targets)\n",
    "#receiver_output = tf.constant(receiver_output)\n",
    "\n",
    "acc = np.sum(targets == receiver_output) / targets.shape[0]\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(input_concepts, receiver_output, targets):\n",
    "    \"\"\"\n",
    "    receiver_output ist was von receiver_sampling zurÃ¼ckgegeben wird\n",
    "    LABELS PRINTEN IN OSSSENKOPF NOTEBOOK\n",
    "    \"\"\"\n",
    "    guesses = []\n",
    "    \n",
    "    for i in range(len(receiver_output)):\n",
    "        guesses.append(input_concepts[i][receiver_output[i]])\n",
    "            \n",
    "    guesses = tf.convert_to_tensor(guesses)\n",
    "    targets = tf.convert_to_tensor(targets)\n",
    "    acc = np.sum(guesses == targets) / guesses.shape[0]\n",
    "    \n",
    "    return -acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sender_entropy_coeff = 0.015 #wie bei Ossenkopf\n",
    "receiver_entropy_coeff = 0.0 # wie bei Ossenkopf\n",
    "\n",
    "\n",
    "game = game = game.Game(sender=sender,\n",
    "                receiver=receiver_encoder,\n",
    "                main_loss=loss,\n",
    "                sender_entr_coeff=sender_entropy_coeff,\n",
    "                receiver_entr_coeff=receiver_entropy_coeff,\n",
    "                batch_size=32,\n",
    "                max_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = tf.keras.optimizers.Adam(learning_rate = 1e-5)\n",
    "\n",
    "for _ in range(10):\n",
    "    with tf.GradientTape() as tape:\n",
    "    \n",
    "        loss, prev_hidden, last_hidden = game(input_concepts, sender_input, targets, receiver_input)\n",
    "        game_gradients = tape.gradient(loss, game.trainable_variables)\n",
    "    \n",
    "    optim.apply_gradients(zip(game_gradients, game.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
