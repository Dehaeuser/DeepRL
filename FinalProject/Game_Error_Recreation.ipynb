{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd69a6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow_probability as tfp\n",
    "from vocab import Vocabulary\n",
    "from env2 import ConceptData\n",
    "from create_data import addFile\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "import create_data\n",
    "from xml.dom import minidom\n",
    "import xml.etree.ElementTree as ET\n",
    "import agents\n",
    "import sender2\n",
    "import game2\n",
    "from agents import find_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13450dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OPTIONS = 10\n",
    "NUM_DISTRACTORS = 9\n",
    "BATCH_SIZE = 32\n",
    "HIDDEN_SIZE = 50\n",
    "EMBED_DIM = 50\n",
    "VOCAB_SIZE = 99\n",
    "MAX_LEN = 10\n",
    "NUM_EPOCHS = 5\n",
    "TRAINING = True\n",
    "SENDER_ALL_INPUT = True\n",
    "sender_entropy_coeff = 0.015 #wie bei Ossenkopf\n",
    "receiver_entropy_coeff = 0.0 # wie bei Ossenkopf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ace1e7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vocabulary = Vocabulary()\n",
    "\n",
    "def addFile(name):\n",
    "    file_name = name + \"_structured_final.xml\"\n",
    "    file = minidom.parse(os.path.join(os.path.join('visa_dataset', 'UK'), file_name))\n",
    "    concepts = file.getElementsByTagName('concept')\n",
    "\n",
    "    for concept in concepts:\n",
    "        vocabulary.addConcept(concept)\n",
    "\n",
    "\n",
    "addFile(\"ANIMALS\")\n",
    "addFile(\"APPLIANCES\")\n",
    "addFile(\"ARTEFACTS\")\n",
    "addFile(\"CLOTHING\")\n",
    "addFile(\"CONTAINER\")\n",
    "addFile(\"DEVICE\")\n",
    "addFile(\"FOOD\")\n",
    "addFile(\"HOME\")\n",
    "addFile(\"INSTRUMENTS\")\n",
    "addFile(\"MATERIAL\")\n",
    "addFile(\"PLANTS\")\n",
    "addFile(\"STRUCTURES\")\n",
    "addFile(\"TOOLS\")\n",
    "addFile(\"TOYS\")\n",
    "addFile(\"VEHICLES\")\n",
    "addFile(\"WEAPONS\")\n",
    "\n",
    "for concept in vocabulary.concept_list:\n",
    "    vocabulary.parseConcept(concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "378cbf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialisiere die Agents\n",
    "sender_encoder = sender2.Sender(hidden_size=EMBED_DIM, num_options=NUM_OPTIONS, batch_size=BATCH_SIZE)\n",
    "sender_LSTM = sender2.Sender_LSTM(agent = sender_encoder,\n",
    "                                    embed_dim=EMBED_DIM,\n",
    "                                    num_cells=1,\n",
    "                                    hidden_size=1, \n",
    "                                    max_len=MAX_LEN,\n",
    "                                see_all_input=SENDER_ALL_INPUT)\n",
    "receiver_encoder = agents.Receiver(hidden_size=EMBED_DIM, num_options = NUM_OPTIONS)\n",
    "receiver_LSTM = agents.Receiver_LSTM(agent=receiver_encoder, \n",
    "                                       vocab_size=VOCAB_SIZE,\n",
    "                                       embed_dim=EMBED_DIM, \n",
    "                                       hidden_size=HIDDEN_SIZE)\n",
    "guesser = agents.AuxiliaryNetwork(hidden_size=HIDDEN_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "588e1d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the losses\n",
    "\n",
    "#loss of guessing the correct target\n",
    "def loss(_sender_input, _message, _receiver_input, input_concepts, receiver_output, targets):\n",
    "    \"\"\"\n",
    "    receiver_output ist was von receiver_sampling zur√ºckgegeben wird\n",
    "    LABELS PRINTEN IN OSSSENKOPF NOTEBOOK\n",
    "    \"\"\"\n",
    "    guesses = []\n",
    "    \n",
    "    for i in range(len(receiver_output)):\n",
    "        guesses.append(input_concepts[i][receiver_output[i]])\n",
    "            \n",
    "    guesses = tf.convert_to_tensor(guesses)\n",
    "    targets = tf.convert_to_tensor(targets)\n",
    "    acc = np.sum(guesses == targets) - np.sum(guesses != targets)\n",
    "        \n",
    "    return -acc\n",
    "\n",
    "#auxiliary loss to promote empathy\n",
    "def auxiliary_loss(receiver_thoughts, \n",
    "                  # _message, _receiver_input, \n",
    "                   guesser_output, \n",
    "                   #_labels,\n",
    "                   weight=0.2):\n",
    "    mae = tf.keras.losses.MeanAbsoluteError(reduction = 'none')\n",
    "    loss = mae(receiver_thoughts, guesser_output)\n",
    "    loss *= weight\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50b59596",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = game2.Game(sender_encoder=sender_encoder,\n",
    "                  sender=sender_LSTM,\n",
    "                receiver=receiver_LSTM,\n",
    "                main_loss=loss,\n",
    "                sender_entr_coeff=sender_entropy_coeff,\n",
    "                receiver_entr_coeff=receiver_entropy_coeff,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                max_len=MAX_LEN,\n",
    "                 sender_all_input=SENDER_ALL_INPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3e91871",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_guesser = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
    "optim_receiver = tf.keras.optimizers.Adam(learning_rate = 1e-2)\n",
    "optim_sender = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
    "#optim_game = tf.keras.optimizers.Adam(learning_rate = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9d6b00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "Receiver_Gradients: \n",
      "[<tf.Tensor: shape=(595, 50), dtype=float32, numpy=\n",
      "array([[-0.16456397,  0.14346646, -0.3199408 , ...,  0.5357647 ,\n",
      "        -0.05965203,  0.40107265],\n",
      "       [-0.08711158,  0.0730034 , -0.14222534, ...,  0.25342387,\n",
      "        -0.03478903,  0.18824095],\n",
      "       [-0.10102054,  0.09999836, -0.20863804, ...,  0.3708167 ,\n",
      "        -0.05760024,  0.28618884],\n",
      "       ...,\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]], dtype=float32)>, <tf.Tensor: shape=(50,), dtype=float32, numpy=\n",
      "array([ 2.26712227e-03, -4.21957672e-03,  1.16969943e-02,  1.92737579e-02,\n",
      "        1.77326053e-03, -1.59012079e-02,  1.51035190e-03, -9.91868973e-03,\n",
      "        2.53975391e-04,  1.73363090e-03, -4.37340140e-03, -2.14666128e-03,\n",
      "       -1.70040131e-03, -2.41398811e-05,  2.99176574e-03, -5.32710552e-03,\n",
      "        1.84990093e-03,  8.92847776e-04, -4.50223684e-04, -5.67264855e-03,\n",
      "        6.18839264e-03, -1.41227245e-03, -7.17261434e-03, -8.56789947e-03,\n",
      "       -1.13497674e-03,  5.66446688e-05, -1.38480067e-02,  1.83311105e-03,\n",
      "       -2.90490985e-02, -1.41748413e-03, -2.25019455e-03,  2.53568590e-03,\n",
      "        4.23052907e-03, -7.29069114e-03,  9.23648477e-03,  3.06646526e-03,\n",
      "       -1.07806921e-03,  6.69270754e-04, -6.09439611e-03, -2.98613310e-03,\n",
      "       -4.46093082e-03,  5.07798791e-03,  1.22309625e-02,  6.36191666e-03,\n",
      "        3.45700979e-03,  2.84023583e-04,  5.57836890e-03, -3.49807739e-03,\n",
      "       -1.37284398e-03, -4.86373901e-04], dtype=float32)>, <tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x000001A47AA22DF0>, <tf.Tensor: shape=(50, 200), dtype=float32, numpy=\n",
      "array([[-8.8828080e-04, -2.6915502e-04, -2.6116977e-05, ...,\n",
      "        -1.8434982e-03,  2.5352137e-04, -1.1029777e-03],\n",
      "       [-2.1892055e-03, -2.6172417e-04,  2.7749245e-04, ...,\n",
      "        -4.6322988e-03,  5.4687675e-04, -2.7419880e-03],\n",
      "       [-6.4655396e-05, -1.2651554e-05,  5.5196550e-05, ...,\n",
      "         2.5753656e-05, -1.7094333e-05,  2.7574282e-05],\n",
      "       ...,\n",
      "       [-1.5643782e-03, -2.2276241e-04,  3.9459090e-04, ...,\n",
      "        -3.1530410e-03,  4.1452196e-04, -1.9100482e-03],\n",
      "       [ 1.8812094e-03,  1.3229442e-04, -4.0242873e-04, ...,\n",
      "         4.4302121e-03, -4.9360114e-04,  2.6146369e-03],\n",
      "       [-1.0592098e-03, -2.4574308e-04,  1.8757876e-04, ...,\n",
      "        -2.0854005e-03,  2.4658965e-04, -1.2717907e-03]], dtype=float32)>, <tf.Tensor: shape=(50, 200), dtype=float32, numpy=\n",
      "array([[-5.6031148e-04, -2.5008485e-04,  2.8794157e-04, ...,\n",
      "        -6.4378686e-04,  1.1020719e-04, -5.9135043e-04],\n",
      "       [ 4.3514528e-04,  3.7575195e-05, -2.2438946e-04, ...,\n",
      "         7.3754636e-04, -9.5158888e-05,  7.3803350e-04],\n",
      "       [-6.3914584e-04,  1.1832409e-05,  1.9842699e-04, ...,\n",
      "        -1.6685500e-03,  2.6887297e-04, -1.3356373e-03],\n",
      "       ...,\n",
      "       [ 1.0892318e-03,  9.1744128e-05, -1.3670023e-04, ...,\n",
      "         3.0739668e-03, -4.4330614e-04,  2.1340714e-03],\n",
      "       [-1.8264646e-04, -6.4314183e-05,  3.1628580e-05, ...,\n",
      "        -2.3919855e-04,  8.2862112e-05, -4.1622054e-04],\n",
      "       [ 9.2150940e-04,  2.6867863e-05, -2.7857459e-04, ...,\n",
      "         2.1308276e-03, -3.0434632e-04,  1.4382302e-03]], dtype=float32)>, <tf.Tensor: shape=(200,), dtype=float32, numpy=\n",
      "array([-5.26555255e-02, -5.67957945e-03,  1.10374726e-02, -6.79930598e-02,\n",
      "        8.55116453e-03, -4.28643413e-02, -3.21306586e-02, -3.46688479e-02,\n",
      "        5.67330942e-02, -9.23180357e-02,  8.12125858e-03, -4.21792408e-03,\n",
      "       -1.61526520e-02,  2.78046504e-02, -5.52069396e-02,  3.39742657e-03,\n",
      "        5.75012062e-03, -2.48744469e-02,  5.78658655e-03,  5.17526530e-02,\n",
      "       -4.70878296e-02, -5.31718358e-02,  1.51560396e-01, -2.32705977e-02,\n",
      "        4.73380350e-02,  1.22166891e-03, -1.10336676e-01, -5.07305795e-03,\n",
      "        1.46362975e-01,  9.10244789e-03,  3.25457230e-02,  1.33530265e-02,\n",
      "        4.70814519e-02,  4.56442405e-03, -4.58173640e-02, -1.02783227e-03,\n",
      "       -4.70753126e-02,  1.68250296e-02,  5.67645691e-02,  4.71180156e-02,\n",
      "       -1.83130987e-02,  2.00220868e-02, -9.24710706e-02, -1.57538671e-02,\n",
      "       -1.64405648e-02, -1.29827252e-02, -1.80549063e-02, -9.43083316e-02,\n",
      "        9.42274183e-03, -5.79505377e-02, -7.35157281e-02, -8.09347909e-03,\n",
      "        2.12632846e-02, -1.00129746e-01,  1.51718603e-02, -2.99961641e-02,\n",
      "       -3.80864032e-02, -4.60249595e-02,  6.05964027e-02, -1.10330380e-01,\n",
      "        7.75531400e-03,  5.43464581e-03, -1.47331459e-02,  2.99884137e-02,\n",
      "       -8.13921914e-02,  6.24795025e-03,  2.02817749e-02, -1.34360520e-02,\n",
      "        1.28841065e-02,  5.34559861e-02, -4.63190116e-02, -6.93605468e-02,\n",
      "        1.67591229e-01, -3.41932364e-02,  5.36440834e-02,  1.85791869e-04,\n",
      "       -1.14556946e-01, -5.76719292e-04,  1.58640832e-01,  3.13794389e-02,\n",
      "        3.08371428e-02,  1.70794651e-02,  7.99368396e-02,  1.85945313e-02,\n",
      "       -5.76089099e-02,  5.61995478e-03, -5.94905429e-02,  2.96925027e-02,\n",
      "        7.53351822e-02,  3.03972233e-02, -2.47707218e-02,  2.98193861e-02,\n",
      "       -1.02208532e-01, -1.87221859e-02, -2.54078619e-02, -3.26899253e-02,\n",
      "       -1.86941139e-02, -1.00599073e-01,  7.47383106e-04, -6.54186532e-02,\n",
      "       -7.83077002e+00,  2.95402288e+00,  1.11989379e-01, -5.85886431e+00,\n",
      "        1.80575407e+00,  7.04761457e+00, -2.29281950e+00,  3.26717210e+00,\n",
      "        7.56006432e+00, -1.11804485e+01, -8.17195356e-01, -1.01066530e+00,\n",
      "        4.80564880e+00,  8.94713497e+00, -8.14585972e+00,  3.17889750e-02,\n",
      "        3.80456638e+00, -6.55001831e+00, -2.59081542e-01,  9.98659229e+00,\n",
      "       -3.89929962e+00, -4.56946707e+00, -9.66589355e+00, -3.07736635e+00,\n",
      "        1.03594494e+01,  5.42489719e+00,  9.24837494e+00, -4.85665846e+00,\n",
      "        1.25232391e+01, -1.92378342e+00, -2.33640075e+00,  6.18821096e+00,\n",
      "        1.65555515e+01, -1.45996451e+00,  3.35989881e+00,  2.29105425e+00,\n",
      "        3.46095657e+00, -3.81635928e+00, -3.97201753e+00,  5.70305395e+00,\n",
      "       -3.75651979e+00,  2.64628077e+00, -1.67347221e+01,  5.08978605e+00,\n",
      "        2.21495819e+00,  4.18807149e-01, -5.21912956e+00,  5.70064926e+00,\n",
      "        5.35760450e+00,  3.93744040e+00, -5.28443120e-02, -5.60196303e-03,\n",
      "        1.11578060e-02, -6.87328056e-02,  8.63720942e-03, -4.31307368e-02,\n",
      "       -3.28541622e-02, -3.47966477e-02,  5.61309606e-02, -9.40448567e-02,\n",
      "        8.14211927e-03, -4.25510947e-03, -1.61750112e-02,  2.69023571e-02,\n",
      "       -5.59127703e-02,  3.39241419e-03,  5.78190433e-03, -2.45098062e-02,\n",
      "        5.79127111e-03,  5.10819778e-02, -4.77809943e-02, -5.26130386e-02,\n",
      "        1.52131155e-01, -2.38410998e-02,  4.82029393e-02,  1.22351060e-03,\n",
      "       -1.09800048e-01, -5.12693683e-03,  1.44923970e-01,  9.23986733e-03,\n",
      "        3.26417796e-02,  1.32820345e-02,  4.79392968e-02,  4.59406059e-03,\n",
      "       -4.62054722e-02, -1.04256219e-03, -4.79476936e-02,  1.65641718e-02,\n",
      "        5.62182069e-02,  4.66025546e-02, -1.87782776e-02,  2.02128887e-02,\n",
      "       -9.27791148e-02, -1.56379584e-02, -1.65065061e-02, -1.30251907e-02,\n",
      "       -1.78602710e-02, -9.63470414e-02,  9.59133822e-03, -5.83835505e-02],\n",
      "      dtype=float32)>]\n",
      "_____________________________________________________________\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "Sender_LSTM_Gradients: \n",
      "[None, None, None, None, None, None, None, None, None, None]\n",
      "_____________________________________________________________\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sender_Encoder_Gradients: \n",
      "[None, None]\n",
      "_____________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable: ['game/sender/sender_encoder/dense/kernel:0', 'game/sender/sender_encoder/dense/bias:0', 'game/sender_lstm/dense_1/kernel:0', 'game/sender_lstm/dense_1/bias:0', 'game/sender_lstm/lstm/lstm_cell/kernel:0', 'game/sender_lstm/lstm/lstm_cell/recurrent_kernel:0', 'game/sender_lstm/lstm/lstm_cell/bias:0', 'game/sender_lstm/lstm_1/lstm_cell_1/kernel:0', 'game/sender_lstm/lstm_1/lstm_cell_1/recurrent_kernel:0', 'game/sender_lstm/lstm_1/lstm_cell_1/bias:0'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-e34102b3bad0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0moptim_receiver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreceiver_gradients\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreceiver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0moptim_sender\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msender_lstm_gradients\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msender\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ReAlly\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[1;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[0mRuntimeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mcalled\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcross\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mreplica\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m     \"\"\"\n\u001b[1;32m--> 598\u001b[1;33m     \u001b[0mgrads_and_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_empty_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ReAlly\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\utils.py\u001b[0m in \u001b[0;36mfilter_empty_gradients\u001b[1;34m(grads_and_vars)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m     raise ValueError(\"No gradients provided for any variable: %s.\" %\n\u001b[0m\u001b[0;32m     79\u001b[0m                      ([v.name for _, v in grads_and_vars],))\n\u001b[0;32m     80\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mvars_with_empty_grads\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No gradients provided for any variable: ['game/sender/sender_encoder/dense/kernel:0', 'game/sender/sender_encoder/dense/bias:0', 'game/sender_lstm/dense_1/kernel:0', 'game/sender_lstm/dense_1/bias:0', 'game/sender_lstm/lstm/lstm_cell/kernel:0', 'game/sender_lstm/lstm/lstm_cell/recurrent_kernel:0', 'game/sender_lstm/lstm/lstm_cell/bias:0', 'game/sender_lstm/lstm_1/lstm_cell_1/kernel:0', 'game/sender_lstm/lstm_1/lstm_cell_1/recurrent_kernel:0', 'game/sender_lstm/lstm_1/lstm_cell_1/bias:0']."
     ]
    }
   ],
   "source": [
    "losses_network = []\n",
    "losses_aux = []\n",
    "\n",
    "for i in range(NUM_EPOCHS):\n",
    "    \n",
    "    data = ConceptData(voc=vocabulary, num_distractors=NUM_DISTRACTORS, batch_size=BATCH_SIZE)\n",
    "    input_concepts, sender_input, targets, receiver_input = data.getInput()\n",
    "    \n",
    "    \n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        \n",
    "        loss, prev_hidden, last_hidden, acc, message = game(input_concepts, sender_input, targets, receiver_input)\n",
    "        losses_network.append(np.mean(loss))\n",
    "        receiver_gradients = tape.gradient(loss, game.receiver.trainable_variables)\n",
    "        print(\"Receiver_Gradients: \")\n",
    "        print(receiver_gradients)\n",
    "        print('_____________________________________________________________')\n",
    "        sender_lstm_gradients = tape.gradient(loss, game.sender.trainable_variables)\n",
    "        print('Sender_LSTM_Gradients: ')\n",
    "        print(sender_lstm_gradients)\n",
    "        print('_____________________________________________________________')\n",
    "        sender_encoder_gradients = tape.gradient(loss, game.sender_encoder.trainable_variables)\n",
    "        print('Sender_Encoder_Gradients: ')\n",
    "        print(sender_encoder_gradients)\n",
    "        print('_____________________________________________________________')\n",
    "\n",
    "    optim_receiver.apply_gradients(zip(receiver_gradients, game.receiver.trainable_variables))\n",
    "    optim_sender.apply_gradients(zip(sender_lstm_gradients, game.sender.trainable_variables))\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        guesser_output = guesser(prev_hidden)\n",
    "        aux_loss = auxiliary_loss(last_hidden, guesser_output)\n",
    "        losses_aux.append(aux_loss)\n",
    "        aux_loss_mean = np.mean(aux_loss)\n",
    "        \n",
    "        aux_gradients = tape.gradient(aux_loss, guesser.trainable_variables)\n",
    "        \n",
    "        # add gradients of guesser onto gradients of sender_encoder to update sender_encoder with these\n",
    "        #sender_encoder_grad_all = []\n",
    "        #for i in range(len(aux_gradients)):\n",
    "            #sender_encoder_grad_all.append(aux_gradients[i] + sender_encoder_gradients[i])\n",
    "        \n",
    "    optim_guesser.apply_gradients(zip(aux_gradients, guesser.trainable_variables))\n",
    "    #optim_sender.apply_gradients(zip(sender_encoder_grad_all, game.sender_encoder.trainable_variables))\n",
    "    print(f'epoch::: {i}   loss::: {np.mean(loss)}   acc::: {acc}   aux_loss::: {aux_loss_mean}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b06ddcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97059458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
