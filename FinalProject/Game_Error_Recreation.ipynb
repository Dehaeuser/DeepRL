{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd69a6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow_probability as tfp\n",
    "from vocab import Vocabulary\n",
    "from env2 import ConceptData\n",
    "from create_data import addFile\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "import create_data\n",
    "from xml.dom import minidom\n",
    "import xml.etree.ElementTree as ET\n",
    "import agents\n",
    "import sender2\n",
    "import game2\n",
    "from agents import find_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13450dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OPTIONS = 10\n",
    "NUM_DISTRACTORS = 9\n",
    "BATCH_SIZE = 32\n",
    "HIDDEN_SIZE = 44\n",
    "EMBED_DIM = 44\n",
    "VOCAB_SIZE = 99\n",
    "MAX_LEN = 10\n",
    "NUM_EPOCHS = 5\n",
    "TRAINING = True\n",
    "SENDER_ALL_INPUT = True\n",
    "sender_entropy_coeff = 0.015 #wie bei Ossenkopf\n",
    "receiver_entropy_coeff = 0.0 # wie bei Ossenkopf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ace1e7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vocabulary = Vocabulary()\n",
    "\n",
    "def addFile(name):\n",
    "    file_name = name + \"_structured_final.xml\"\n",
    "    file = minidom.parse(os.path.join(os.path.join('visa_dataset', 'UK'), file_name))\n",
    "    concepts = file.getElementsByTagName('concept')\n",
    "\n",
    "    for concept in concepts:\n",
    "        vocabulary.addConcept(concept)\n",
    "\n",
    "\n",
    "addFile(\"ANIMALS\")\n",
    "addFile(\"APPLIANCES\")\n",
    "addFile(\"ARTEFACTS\")\n",
    "addFile(\"CLOTHING\")\n",
    "addFile(\"CONTAINER\")\n",
    "addFile(\"DEVICE\")\n",
    "addFile(\"FOOD\")\n",
    "addFile(\"HOME\")\n",
    "addFile(\"INSTRUMENTS\")\n",
    "addFile(\"MATERIAL\")\n",
    "addFile(\"PLANTS\")\n",
    "addFile(\"STRUCTURES\")\n",
    "addFile(\"TOOLS\")\n",
    "addFile(\"TOYS\")\n",
    "addFile(\"VEHICLES\")\n",
    "addFile(\"WEAPONS\")\n",
    "\n",
    "for concept in vocabulary.concept_list:\n",
    "    vocabulary.parseConcept(concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "378cbf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialisiere die Agents\n",
    "sender_encoder = sender2.Sender(num_options=NUM_OPTIONS, batch_size=BATCH_SIZE)\n",
    "sender_LSTM = sender2.Sender_LSTM(agent = sender_encoder,\n",
    "                                    embed_dim=EMBED_DIM,\n",
    "                                    num_cells=1,\n",
    "                                    hidden_size=1, \n",
    "                                    max_len=MAX_LEN,\n",
    "                                see_all_input=SENDER_ALL_INPUT)\n",
    "receiver_encoder = agents.Receiver(num_options = NUM_OPTIONS)\n",
    "receiver_LSTM = agents.Receiver_LSTM(agent=receiver_encoder, \n",
    "                                       vocab_size=VOCAB_SIZE,\n",
    "                                       embed_dim=EMBED_DIM, \n",
    "                                       hidden_size=HIDDEN_SIZE)\n",
    "guesser = agents.AuxiliaryNetwork(hidden_size=HIDDEN_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "588e1d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the losses\n",
    "\n",
    "#loss of guessing the correct target\n",
    "def loss(_sender_input, _message, _receiver_input, input_concepts, receiver_output, targets):\n",
    "    \"\"\"\n",
    "    receiver_output ist was von receiver_sampling zur√ºckgegeben wird\n",
    "    LABELS PRINTEN IN OSSSENKOPF NOTEBOOK\n",
    "    \"\"\"\n",
    "    guesses = []\n",
    "    \n",
    "    for i in range(len(receiver_output)):\n",
    "        guesses.append(input_concepts[i][receiver_output[i]])\n",
    "            \n",
    "    guesses = tf.convert_to_tensor(guesses)\n",
    "    targets = tf.convert_to_tensor(targets)\n",
    "    acc = np.sum(guesses == targets) / guesses.shape[0]\n",
    "    #acc = np.sum(guesses == targets) - np.sum(guesses != targets)\n",
    "        \n",
    "    return -acc\n",
    "\n",
    "#auxiliary loss to promote empathy\n",
    "def auxiliary_loss(receiver_thoughts, \n",
    "                  # _message, _receiver_input, \n",
    "                   guesser_output, \n",
    "                   #_labels,\n",
    "                   weight=0.2):\n",
    "    mae = tf.keras.losses.MeanAbsoluteError(reduction = 'none')\n",
    "    loss = mae(receiver_thoughts, guesser_output)\n",
    "    loss *= weight\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50b59596",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = game2.Game(sender_encoder=sender_encoder,\n",
    "                  sender=sender_LSTM,\n",
    "                receiver=receiver_LSTM,\n",
    "                main_loss=loss,\n",
    "                sender_entr_coeff=sender_entropy_coeff,\n",
    "                receiver_entr_coeff=receiver_entropy_coeff,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                max_len=MAX_LEN,\n",
    "                 sender_all_input=SENDER_ALL_INPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3e91871",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_guesser = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
    "optim_receiver = tf.keras.optimizers.Adam(learning_rate = 1e-2)\n",
    "optim_sender = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
    "#optim_game = tf.keras.optimizers.Adam(learning_rate = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9d6b00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "Receiver_Gradients: \n",
      "[<tf.Tensor: shape=(595, 44), dtype=float32, numpy=\n",
      "array([[-6.1779644e-04,  1.5259060e-04, -4.1328566e-04, ...,\n",
      "         1.1298083e-03, -5.0625857e-04, -7.5530540e-04],\n",
      "       [-6.4476248e-05, -8.7125391e-06, -3.9207545e-05, ...,\n",
      "         1.1605015e-04, -4.3182568e-05, -5.6411038e-05],\n",
      "       [-3.5140413e-04,  3.3492255e-05, -3.0315627e-04, ...,\n",
      "         7.8415388e-04, -4.3299765e-04, -4.5476141e-04],\n",
      "       ...,\n",
      "       [ 2.0307676e-04, -3.0125218e-05,  1.6455911e-04, ...,\n",
      "        -3.9061290e-04,  2.1059121e-04,  2.4883324e-04],\n",
      "       [ 2.0307676e-04, -3.0125218e-05,  1.6455911e-04, ...,\n",
      "        -3.9061290e-04,  2.1059121e-04,  2.4883324e-04],\n",
      "       [ 2.0307676e-04, -3.0125218e-05,  1.6455911e-04, ...,\n",
      "        -3.9061290e-04,  2.1059121e-04,  2.4883324e-04]], dtype=float32)>, <tf.Tensor: shape=(44,), dtype=float32, numpy=\n",
      "array([ 7.5150456e-07, -2.2705572e-06,  1.1830562e-06,  1.0643547e-05,\n",
      "        2.4145418e-05,  3.2290991e-06, -1.2382239e-05, -9.1318907e-07,\n",
      "        4.7268550e-06,  6.1475876e-06, -4.2217944e-06, -1.0625008e-05,\n",
      "        1.0214746e-05,  1.5408441e-06,  8.1177423e-06, -9.1589754e-07,\n",
      "        1.2915843e-06, -1.3917132e-05, -2.5100395e-05,  7.9187885e-06,\n",
      "        1.2353004e-05,  1.4732523e-06,  5.9425656e-07, -1.0733183e-06,\n",
      "       -1.1797223e-05, -3.3254983e-06,  7.5381831e-07, -1.0720833e-06,\n",
      "        7.7737495e-06, -1.3478508e-05, -1.2779870e-05, -2.2801978e-06,\n",
      "        2.8247377e-06,  7.9857564e-05, -9.9330937e-06,  3.0887677e-06,\n",
      "        6.7073124e-06, -6.1752544e-06, -1.4295598e-05,  4.8679431e-07,\n",
      "        7.2072453e-07,  6.9329340e-05, -1.7747880e-05, -7.5701246e-06],\n",
      "      dtype=float32)>, <tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x0000022B31714DF0>, <tf.Tensor: shape=(44, 176), dtype=float32, numpy=\n",
      "array([[ 5.57878366e-09,  4.67827732e-08,  4.60729666e-07, ...,\n",
      "         2.60983256e-06, -2.07535649e-07, -1.50360631e-08],\n",
      "       [ 6.46098101e-07,  6.95753329e-07,  5.71719420e-06, ...,\n",
      "         2.64487062e-05, -2.64560140e-06, -2.86807506e-07],\n",
      "       [-2.67478441e-07, -3.55745868e-07, -2.88267688e-06, ...,\n",
      "        -1.36767967e-05,  1.41196881e-06,  1.32854765e-07],\n",
      "       ...,\n",
      "       [-1.00830547e-07,  8.72458656e-08, -2.47920389e-06, ...,\n",
      "        -1.14408722e-05,  1.02966760e-06,  1.03677074e-07],\n",
      "       [ 2.67879159e-07,  1.01086584e-07,  1.27910516e-06, ...,\n",
      "         6.87182273e-06, -6.74098033e-07, -3.10066355e-08],\n",
      "       [ 3.64765754e-07,  1.10805490e-06,  6.56042903e-06, ...,\n",
      "         3.02204026e-05, -2.93949347e-06, -1.95947479e-07]], dtype=float32)>, <tf.Tensor: shape=(44, 176), dtype=float32, numpy=\n",
      "array([[ 2.9686112e-07,  3.7828784e-07,  1.6071754e-06, ...,\n",
      "         1.1172002e-05, -8.6069036e-07, -6.0668043e-07],\n",
      "       [ 3.6371833e-07, -1.2371713e-07, -4.7904609e-07, ...,\n",
      "        -2.8173079e-06,  9.8613448e-08,  3.7503165e-07],\n",
      "       [ 3.9604194e-07,  1.3182586e-07,  1.5455998e-06, ...,\n",
      "         7.5813050e-06, -4.9236075e-07, -2.2889813e-07],\n",
      "       ...,\n",
      "       [-7.4428056e-07, -4.8735802e-07, -3.6832539e-06, ...,\n",
      "        -1.9752302e-05,  1.5179123e-06,  8.4766577e-07],\n",
      "       [-2.0212278e-07,  6.4702476e-08,  2.0061300e-06, ...,\n",
      "         8.8479974e-06, -1.1557507e-06, -5.9736561e-07],\n",
      "       [ 3.9514259e-07,  2.9688067e-07,  2.5107233e-06, ...,\n",
      "         1.3665698e-05, -8.1497694e-07, -4.3694570e-07]], dtype=float32)>, <tf.Tensor: shape=(176,), dtype=float32, numpy=\n",
      "array([-2.79692413e-05, -2.07251796e-05, -1.44320918e-04,  2.39104760e-04,\n",
      "        2.80820183e-04,  1.13274960e-04,  2.30702371e-05, -1.04264591e-05,\n",
      "       -2.34025320e-05,  3.46777961e-05,  1.49141008e-04, -2.15985376e-04,\n",
      "        5.93245477e-06, -2.14566186e-04,  3.77536053e-05,  4.93814787e-06,\n",
      "       -1.81988726e-04,  2.30004458e-04,  9.70418623e-05, -7.27563602e-05,\n",
      "        1.03782062e-04, -1.55817415e-05, -4.80114722e-05,  1.92779407e-05,\n",
      "       -1.18403150e-04, -2.95635455e-05,  5.01527611e-05, -3.28506103e-05,\n",
      "       -7.46504447e-05, -1.09368601e-04, -5.42797679e-05,  4.47880411e-05,\n",
      "        1.12842674e-04, -3.23042943e-04,  4.31959506e-06, -8.78046631e-05,\n",
      "       -5.34798573e-06,  3.97256190e-05,  1.59776988e-04, -4.38156621e-06,\n",
      "       -1.55790076e-05, -6.39426755e-04,  6.78516299e-05,  2.77244385e-06,\n",
      "       -4.41317170e-05, -3.16645383e-05, -1.80654009e-04,  2.47844757e-04,\n",
      "        3.37604142e-04,  1.02805621e-04,  5.72757854e-05, -2.57727170e-05,\n",
      "       -6.88556538e-05,  3.64590342e-05,  1.41358993e-04, -2.36390755e-04,\n",
      "        1.93413689e-05, -2.01297371e-04,  5.40542969e-05, -1.17605186e-05,\n",
      "       -1.72305954e-04,  2.34436025e-04,  1.07228763e-04, -6.73469840e-05,\n",
      "        1.22437195e-04, -3.00846841e-05, -5.09898491e-05,  2.37002350e-05,\n",
      "       -1.22369544e-04, -4.72416468e-05,  3.36380363e-05,  6.47001707e-06,\n",
      "       -7.53783534e-05, -8.51220320e-05, -4.38109491e-05,  5.95632191e-05,\n",
      "        1.05470390e-04, -3.74314084e-04,  6.11948144e-06, -1.20967736e-04,\n",
      "       -2.12710729e-05,  7.53422282e-05,  1.56510592e-04,  7.24409892e-06,\n",
      "       -3.74998781e-05, -6.96640171e-04,  8.33723680e-05,  5.11004218e-05,\n",
      "       -3.15078418e-04, -1.62224495e-03,  2.07987484e-02, -2.51709484e-02,\n",
      "        4.08212654e-02, -6.05364796e-03, -1.41602091e-03, -6.12899289e-03,\n",
      "        1.21510662e-02, -5.54630673e-03,  3.37625220e-02,  2.01837309e-02,\n",
      "        2.97663477e-03,  1.36560518e-02,  3.15114576e-03, -3.94278322e-04,\n",
      "        1.86279099e-02, -1.45134283e-02,  1.02659231e-02,  2.59673153e-03,\n",
      "        5.09877363e-03,  4.37368872e-03,  2.71914923e-03, -8.41949414e-03,\n",
      "        8.28091428e-03,  8.50621052e-03,  3.91658731e-02, -7.52555020e-03,\n",
      "        6.77565672e-03, -1.22968210e-02, -1.45608885e-03,  1.85977900e-03,\n",
      "        2.35959943e-02, -1.65461451e-02,  7.21881406e-06,  1.47460122e-02,\n",
      "        1.08487811e-03, -1.58833675e-02, -1.45066362e-02, -1.85577956e-03,\n",
      "       -4.12356900e-03, -3.87610383e-02, -6.46716822e-03, -5.35286497e-04,\n",
      "       -2.79253782e-05, -2.04592216e-05, -1.41812925e-04,  2.42709022e-04,\n",
      "        2.89607531e-04,  1.15562354e-04,  2.34664367e-05, -1.02674840e-05,\n",
      "       -2.29002617e-05,  3.49831535e-05,  1.50190201e-04, -2.16151981e-04,\n",
      "        6.33680884e-06, -2.21638402e-04,  3.77881297e-05,  5.06405104e-06,\n",
      "       -1.85502533e-04,  2.30999998e-04,  9.61840269e-05, -7.37397495e-05,\n",
      "        1.03051891e-04, -1.56038259e-05, -4.70384912e-05,  1.95710109e-05,\n",
      "       -1.17943404e-04, -2.99891217e-05,  4.89413142e-05, -3.18909042e-05,\n",
      "       -7.58158712e-05, -1.06785250e-04, -5.56859995e-05,  4.48498176e-05,\n",
      "        1.12652808e-04, -3.14045988e-04,  4.48147421e-06, -8.58609274e-05,\n",
      "       -5.51028097e-06,  4.00073259e-05,  1.57591712e-04, -4.54756082e-06,\n",
      "       -1.59024421e-05, -6.41186838e-04,  6.69422952e-05,  2.62794947e-06],\n",
      "      dtype=float32)>]\n",
      "_____________________________________________________________\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "Sender_LSTM_Gradients: \n",
      "[None, None, None, None, None, None, None, None, None, None]\n",
      "_____________________________________________________________\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "Sender_Encoder_Gradients: \n",
      "[None, None]\n",
      "_____________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable: ['game/sender/sender_encoder/dense/kernel:0', 'game/sender/sender_encoder/dense/bias:0', 'game/sender_lstm/dense_1/kernel:0', 'game/sender_lstm/dense_1/bias:0', 'game/sender_lstm/lstm/lstm_cell/kernel:0', 'game/sender_lstm/lstm/lstm_cell/recurrent_kernel:0', 'game/sender_lstm/lstm/lstm_cell/bias:0', 'game/sender_lstm/lstm_1/lstm_cell_1/kernel:0', 'game/sender_lstm/lstm_1/lstm_cell_1/recurrent_kernel:0', 'game/sender_lstm/lstm_1/lstm_cell_1/bias:0'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-bef2d2a3ba26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0moptim_receiver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreceiver_gradients\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreceiver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0moptim_sender\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msender_lstm_gradients\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msender\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ReAlly\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[1;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[0mRuntimeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mcalled\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcross\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mreplica\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m     \"\"\"\n\u001b[1;32m--> 598\u001b[1;33m     \u001b[0mgrads_and_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_empty_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ReAlly\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\utils.py\u001b[0m in \u001b[0;36mfilter_empty_gradients\u001b[1;34m(grads_and_vars)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m     raise ValueError(\"No gradients provided for any variable: %s.\" %\n\u001b[0m\u001b[0;32m     79\u001b[0m                      ([v.name for _, v in grads_and_vars],))\n\u001b[0;32m     80\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mvars_with_empty_grads\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No gradients provided for any variable: ['game/sender/sender_encoder/dense/kernel:0', 'game/sender/sender_encoder/dense/bias:0', 'game/sender_lstm/dense_1/kernel:0', 'game/sender_lstm/dense_1/bias:0', 'game/sender_lstm/lstm/lstm_cell/kernel:0', 'game/sender_lstm/lstm/lstm_cell/recurrent_kernel:0', 'game/sender_lstm/lstm/lstm_cell/bias:0', 'game/sender_lstm/lstm_1/lstm_cell_1/kernel:0', 'game/sender_lstm/lstm_1/lstm_cell_1/recurrent_kernel:0', 'game/sender_lstm/lstm_1/lstm_cell_1/bias:0']."
     ]
    }
   ],
   "source": [
    "losses_network = []\n",
    "losses_aux = []\n",
    "\n",
    "for i in range(NUM_EPOCHS):\n",
    "    \n",
    "    data = ConceptData(voc=vocabulary, num_distractors=NUM_DISTRACTORS, batch_size=BATCH_SIZE)\n",
    "    input_concepts, sender_input, targets, receiver_input = data.getInput()\n",
    "    \n",
    "    \n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        \n",
    "        loss, prev_hidden, last_hidden, acc, message = game(input_concepts, sender_input, targets, receiver_input)\n",
    "        losses_network.append(np.mean(loss))\n",
    "        receiver_gradients = tape.gradient(loss, game.receiver.trainable_variables)\n",
    "        print(\"Receiver_Gradients: \")\n",
    "        print(receiver_gradients)\n",
    "        print('_____________________________________________________________')\n",
    "        sender_lstm_gradients = tape.gradient(loss, game.sender.trainable_variables)\n",
    "        print('Sender_LSTM_Gradients: ')\n",
    "        print(sender_lstm_gradients)\n",
    "        print('_____________________________________________________________')\n",
    "        sender_encoder_gradients = tape.gradient(loss, game.sender_encoder.trainable_variables)\n",
    "        print('Sender_Encoder_Gradients: ')\n",
    "        print(sender_encoder_gradients)\n",
    "        print('_____________________________________________________________')\n",
    "\n",
    "    optim_receiver.apply_gradients(zip(receiver_gradients, game.receiver.trainable_variables))\n",
    "    optim_sender.apply_gradients(zip(sender_lstm_gradients, game.sender.trainable_variables))\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        guesser_output = guesser(prev_hidden)\n",
    "        aux_loss = auxiliary_loss(last_hidden, guesser_output)\n",
    "        losses_aux.append(aux_loss)\n",
    "        aux_loss_mean = np.mean(aux_loss)\n",
    "        \n",
    "        aux_gradients = tape.gradient(aux_loss, guesser.trainable_variables)\n",
    "        \n",
    "        # add gradients of guesser onto gradients of sender_encoder to update sender_encoder with these\n",
    "        #sender_encoder_grad_all = []\n",
    "        #for i in range(len(aux_gradients)):\n",
    "            #sender_encoder_grad_all.append(aux_gradients[i] + sender_encoder_gradients[i])\n",
    "        \n",
    "    optim_guesser.apply_gradients(zip(aux_gradients, guesser.trainable_variables))\n",
    "    #optim_sender.apply_gradients(zip(sender_encoder_grad_all, game.sender_encoder.trainable_variables))\n",
    "    print(f'epoch::: {i}   loss::: {np.mean(loss)}   acc::: {acc}   aux_loss::: {aux_loss_mean}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b06ddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97059458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
