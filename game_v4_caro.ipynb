{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd69a6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow_probability as tfp\n",
    "from vocab import Vocabulary\n",
    "from env2 import ConceptData\n",
    "from create_data import addFile\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "import create_data\n",
    "from xml.dom import minidom\n",
    "import xml.etree.ElementTree as ET\n",
    "import agents\n",
    "import sender\n",
    "import game\n",
    "from agents import find_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13450dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OPTIONS = 10\n",
    "NUM_DISTRACTORS = 9\n",
    "BATCH_SIZE = 32\n",
    "HIDDEN_SIZE = 44\n",
    "EMBED_DIM = 44\n",
    "VOCAB_SIZE = 99\n",
    "MAX_LEN = 10\n",
    "NUM_EPOCHS = 1\n",
    "TRAINING = True\n",
    "sender_entropy_coeff = 0.015 #wie bei Ossenkopf\n",
    "receiver_entropy_coeff = 0.0 # wie bei Ossenkopf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ace1e7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vocabulary = Vocabulary()\n",
    "\n",
    "def addFile(name):\n",
    "    file_name = name + \"_structured_final.xml\"\n",
    "    file = minidom.parse(os.path.join(os.path.join('visa_dataset', 'UK'), file_name))\n",
    "    concepts = file.getElementsByTagName('concept')\n",
    "\n",
    "    for concept in concepts:\n",
    "        vocabulary.addConcept(concept)\n",
    "\n",
    "\n",
    "addFile(\"ANIMALS\")\n",
    "addFile(\"APPLIANCES\")\n",
    "addFile(\"ARTEFACTS\")\n",
    "addFile(\"CLOTHING\")\n",
    "addFile(\"CONTAINER\")\n",
    "addFile(\"DEVICE\")\n",
    "addFile(\"FOOD\")\n",
    "addFile(\"HOME\")\n",
    "addFile(\"INSTRUMENTS\")\n",
    "addFile(\"MATERIAL\")\n",
    "addFile(\"PLANTS\")\n",
    "addFile(\"STRUCTURES\")\n",
    "addFile(\"TOOLS\")\n",
    "addFile(\"TOYS\")\n",
    "addFile(\"VEHICLES\")\n",
    "addFile(\"WEAPONS\")\n",
    "\n",
    "for concept in vocabulary.concept_list:\n",
    "    vocabulary.parseConcept(concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "378cbf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialisiere die Agents\n",
    "speakerEncoder = sender.Sender(num_options=NUM_OPTIONS, batch_size=BATCH_SIZE)\n",
    "speakerEncoderOnlyTarget = sender.SenderOnlyTarget(batch_size=BATCH_SIZE)\n",
    "speakerDecoder = sender.Sender_LSTM(agent = speakerEncoder,\n",
    "                                    embed_dim=EMBED_DIM,\n",
    "                                    num_cells=1,\n",
    "                                    hidden_size=1, \n",
    "                                    max_len=MAX_LEN)\n",
    "receiverEncoder = agents.Receiver(num_options = NUM_OPTIONS)\n",
    "receiverDecoder = agents.Receiver_LSTM(agent=receiverEncoder, \n",
    "                                       vocab_size=VOCAB_SIZE,\n",
    "                                       embed_dim=EMBED_DIM, \n",
    "                                       hidden_size=HIDDEN_SIZE)\n",
    "guesser = agents.AuxiliaryNetwork(hidden_size=HIDDEN_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "588e1d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the losses\n",
    "\n",
    "#loss of guessing the correct target\n",
    "def loss(input_concepts, receiver_output, targets):\n",
    "    \"\"\"\n",
    "    receiver_output ist was von receiver_sampling zur√ºckgegeben wird\n",
    "    LABELS PRINTEN IN OSSSENKOPF NOTEBOOK\n",
    "    \"\"\"\n",
    "    guesses = []\n",
    "    \n",
    "    for i in range(len(receiver_output)):\n",
    "        guesses.append(input_concepts[i][receiver_output[i]])\n",
    "            \n",
    "    guesses = tf.constant(guesses)\n",
    "    targets = tf.constant(targets)\n",
    "    acc = np.sum(guesses == targets) / guesses.shape[0]\n",
    "    \n",
    "    return -acc\n",
    "\n",
    "#auxiliary loss to promote empathy\n",
    "def auxiliary_loss(receiver_thoughts, \n",
    "                  # _message, _receiver_input, \n",
    "                   guesser_output, \n",
    "                   #_labels,\n",
    "                   weight=0.2):\n",
    "    mae = tf.keras.losses.MeanAbsoluteError(reduction = 'none')\n",
    "    loss = mae(receiver_thoughts, guesser_output)\n",
    "    loss *= weight\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50b59596",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = game.Game(sender=speakerDecoder,\n",
    "                receiver=receiverDecoder,\n",
    "                main_loss=loss,\n",
    "                sender_entr_coeff=sender_entropy_coeff,\n",
    "                receiver_entr_coeff=receiver_entropy_coeff,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                max_len=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3e91871",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_guesser = tf.keras.optimizers.Adam(learning_rate = 1e-2)\n",
    "#optim_receiver = tf.keras.optimizers.Adam(learning_rate = 1e-2)\n",
    "#optim_sender = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
    "optim_game = tf.keras.optimizers.Adam(learning_rate = 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9d6b00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape sender input:\n",
      "(32, 10, 1, 595)\n",
      "32\n",
      "input-shape:\n",
      "(32, 10, 44)\n",
      "10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['game/sender_lstm/sender/sender_encoder/dense/kernel:0', 'game/sender_lstm/sender/sender_encoder/dense/bias:0', 'game/sender_lstm/dense_2/kernel:0', 'game/sender_lstm/dense_2/bias:0', 'game/sender_lstm/lstm/lstm_cell/kernel:0', 'game/sender_lstm/lstm/lstm_cell/recurrent_kernel:0', 'game/sender_lstm/lstm/lstm_cell/bias:0'] when minimizing the loss.\n"
     ]
    }
   ],
   "source": [
    "for i in range(NUM_EPOCHS):\n",
    "    # 1. data holen, labels?\n",
    "    ####Fehlt hier noch\n",
    "    data = ConceptData(voc=vocabulary, num_distractors=NUM_DISTRACTORS, batch_size=BATCH_SIZE)\n",
    "    input_concepts, sender_input, targets, receiver_input = data.getInput()\n",
    "    \n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        loss, prev_hidden, last_hidden = game(input_concepts, sender_input, targets, receiver_input)\n",
    "        game_gradients = tape.gradient(loss, game.trainable_variables)\n",
    "    \n",
    "    optim_game.apply_gradients(zip(game_gradients, game.trainable_variables))\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        guesser_output = guesser(prev_hidden)\n",
    "        aux_loss = auxiliary_loss(last_hidden, guesser_output)\n",
    "        \n",
    "        aux_gradients = tape.gradient(aux_loss, guesser.trainable_variables)\n",
    "        \n",
    "    optim_guesser.apply_gradients(zip(aux_gradients, guesser.trainable_variables))\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b06ddcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
