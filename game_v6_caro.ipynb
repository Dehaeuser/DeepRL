{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd69a6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow_probability as tfp\n",
    "from vocab import Vocabulary\n",
    "from env2 import ConceptData\n",
    "from create_data import addFile\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "import create_data\n",
    "from xml.dom import minidom\n",
    "import xml.etree.ElementTree as ET\n",
    "import agents\n",
    "import sender2\n",
    "import game2\n",
    "from agents import find_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13450dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OPTIONS = 10\n",
    "NUM_DISTRACTORS = 9\n",
    "BATCH_SIZE = 32\n",
    "HIDDEN_SIZE = 44\n",
    "EMBED_DIM = 44\n",
    "VOCAB_SIZE = 99\n",
    "MAX_LEN = 10\n",
    "NUM_EPOCHS = 2\n",
    "TRAINING = True\n",
    "SENDER_ALL_INPUT = True\n",
    "sender_entropy_coeff = 0.015 #wie bei Ossenkopf\n",
    "receiver_entropy_coeff = 0.0 # wie bei Ossenkopf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ace1e7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vocabulary = Vocabulary()\n",
    "\n",
    "def addFile(name):\n",
    "    file_name = name + \"_structured_final.xml\"\n",
    "    file = minidom.parse(os.path.join(os.path.join('visa_dataset', 'UK'), file_name))\n",
    "    concepts = file.getElementsByTagName('concept')\n",
    "\n",
    "    for concept in concepts:\n",
    "        vocabulary.addConcept(concept)\n",
    "\n",
    "\n",
    "addFile(\"ANIMALS\")\n",
    "addFile(\"APPLIANCES\")\n",
    "addFile(\"ARTEFACTS\")\n",
    "addFile(\"CLOTHING\")\n",
    "addFile(\"CONTAINER\")\n",
    "addFile(\"DEVICE\")\n",
    "addFile(\"FOOD\")\n",
    "addFile(\"HOME\")\n",
    "addFile(\"INSTRUMENTS\")\n",
    "addFile(\"MATERIAL\")\n",
    "addFile(\"PLANTS\")\n",
    "addFile(\"STRUCTURES\")\n",
    "addFile(\"TOOLS\")\n",
    "addFile(\"TOYS\")\n",
    "addFile(\"VEHICLES\")\n",
    "addFile(\"WEAPONS\")\n",
    "\n",
    "for concept in vocabulary.concept_list:\n",
    "    vocabulary.parseConcept(concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "378cbf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialisiere die Agents\n",
    "sender_encoder = sender2.Sender(num_options=NUM_OPTIONS, batch_size=BATCH_SIZE)\n",
    "sender_encoder_only_target = sender2.SenderOnlyTarget(batch_size=BATCH_SIZE)\n",
    "sender_LSTM = sender2.Sender_LSTM(embed_dim=EMBED_DIM,\n",
    "                                    num_cells=1,\n",
    "                                    hidden_size=1, \n",
    "                                    max_len=MAX_LEN,\n",
    "                                see_all_input=SENDER_ALL_INPUT)\n",
    "receiver_encoder = agents.Receiver(num_options = NUM_OPTIONS)\n",
    "receiver_LSTM = agents.Receiver_LSTM(agent=receiver_encoder, \n",
    "                                       vocab_size=VOCAB_SIZE,\n",
    "                                       embed_dim=EMBED_DIM, \n",
    "                                       hidden_size=HIDDEN_SIZE)\n",
    "guesser = agents.AuxiliaryNetwork(hidden_size=HIDDEN_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "588e1d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the losses\n",
    "\n",
    "#loss of guessing the correct target\n",
    "def loss(_sender_input, _sender_lstm_input, _message, _receiver_input, input_concepts, receiver_output, targets):\n",
    "    \"\"\"\n",
    "    receiver_output ist was von receiver_sampling zur√ºckgegeben wird\n",
    "    LABELS PRINTEN IN OSSSENKOPF NOTEBOOK\n",
    "    \"\"\"\n",
    "    guesses = []\n",
    "    \n",
    "    for i in range(len(receiver_output)):\n",
    "        guesses.append(input_concepts[i][receiver_output[i]])\n",
    "            \n",
    "    guesses = tf.convert_to_tensor(guesses)\n",
    "    targets = tf.convert_to_tensor(targets)\n",
    "    acc = np.sum(guesses == targets) - np.sum(guesses != targets)\n",
    "    \n",
    "    return -acc\n",
    "\n",
    "#auxiliary loss to promote empathy\n",
    "def auxiliary_loss(receiver_thoughts, \n",
    "                   _message, _receiver_input, \n",
    "                   guesser_output, \n",
    "                   _labels,\n",
    "                   weight=0.2):\n",
    "    mae = tf.keras.losses.MeanAbsoluteError(reduction = 'none')\n",
    "    loss = mae(receiver_thoughts, guesser_output)\n",
    "    loss *= weight\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50b59596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable_variables:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "game = game2.Game(sender_encoder=sender_encoder,\n",
    "                  sender=sender_LSTM,\n",
    "                receiver=receiver_LSTM,\n",
    "                main_loss=loss,\n",
    "                sender_entr_coeff=sender_entropy_coeff,\n",
    "                receiver_entr_coeff=receiver_entropy_coeff,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                max_len=MAX_LEN,\n",
    "                 sender_all_input=SENDER_ALL_INPUT)\n",
    "print(\"trainable_variables:\")\n",
    "print(game.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3e91871",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_guesser = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
    "#optim_receiver = tf.keras.optimizers.Adam(learning_rate = 1e-2)\n",
    "#optim_sender = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
    "optim_game = tf.keras.optimizers.Adam(learning_rate = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9d6b00d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable <tf.Variable 'game/receiver_lstm/receiver/encoder/dense_3/kernel:0' shape=(595, 44) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-9b16d2a06a82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m#print(\"gradients: \", game_grads)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0moptim_game\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreceiver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0moptim_game\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame_grads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m#optim_game.apply_gradients(zip(sender_lstm_gradients, game.sender.trainable_variables))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ReAlly\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mget_gradients\u001b[1;34m(self, loss, params)\u001b[0m\n\u001b[0;32m    717\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgrad\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m           raise ValueError(\"Variable {} has `None` for gradient. \"\n\u001b[0m\u001b[0;32m    720\u001b[0m                            \u001b[1;34m\"Please make sure that all of your ops have a \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m                            \u001b[1;34m\"gradient defined (i.e. are differentiable). \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Variable <tf.Variable 'game/receiver_lstm/receiver/encoder/dense_3/kernel:0' shape=(595, 44) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval."
     ]
    }
   ],
   "source": [
    "losses_network = []\n",
    "losses_aux = []\n",
    "\n",
    "for i in range(NUM_EPOCHS):\n",
    "    # 1. data holen, labels?\n",
    "    ####Fehlt hier noch\n",
    "    data = ConceptData(voc=vocabulary, num_distractors=NUM_DISTRACTORS, batch_size=BATCH_SIZE)\n",
    "    input_concepts, sender_input, targets, receiver_input = data.getInput()\n",
    "    \n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        #print(\"trainable_variables:\")\n",
    "        #print(game.trainable_variables)\n",
    "        loss, prev_hidden, last_hidden, acc, message = game(input_concepts, sender_input, targets, receiver_input)\n",
    "        losses_network.append(np.mean(loss))\n",
    "        game_grads = tape.gradient(loss, game.trainable_variables)\n",
    "        #print(\"sender_train: \", game.sender.trainable_variables)\n",
    "        #print(\"sender_encoder_grad: \", sender_encoder_gradients)\n",
    "        #print(\"trainable variables: \", game.trainable_variables)\n",
    "        #print(\"gradients: \", game_grads)\n",
    "    \n",
    "    optim_game.apply_gradients(zip(game_grads, game.trainable_variables))\n",
    "    #optim_game.apply_gradients(zip(sender_lstm_gradients, game.sender.trainable_variables))\n",
    "    # (grad, var) for (grad, var) in zip(game_gradients, game.trainable_variables) if grad is not None\n",
    "    \n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        \n",
    "        guesser_output = guesser(prev_hidden)\n",
    "        aux_loss = auxiliary_loss(last_hidden, message, receiver_input, guesser_output, targets)\n",
    "        losses_aux.append(aux_loss)\n",
    "        aux_loss_mean = np.mean(aux_loss)\n",
    "        \n",
    "        aux_gradients = tape.gradient(aux_loss, guesser.trainable_variables)\n",
    "        \n",
    "    sender_encoder_grad_all = []\n",
    "    for i in range(len(aux_gradients)):\n",
    "        sender_encoder_grad_all.append(aux_gradients[i] + sender_encoder_gradients[i])\n",
    "    \n",
    "    optim_game.apply_gradients(zip(sender_encoder_grad_all, game.sender_encoder.trainable_variables))\n",
    "    optim_guesser.apply_gradients(zip(aux_gradients, guesser.trainable_variables))\n",
    "    print(f'epoch::: {i}   loss::: {np.mean(loss)}   acc::: {acc}   aux_loss::: {aux_loss_mean}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b06ddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97059458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
